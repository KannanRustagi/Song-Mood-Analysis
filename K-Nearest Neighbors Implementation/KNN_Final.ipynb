{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["# k-nearest neighbors on the Iris Flowers Dataset\n","from random import seed\n","from random import randrange\n","from csv import reader\n","from math import sqrt\n","import numpy as np\n","# Load a CSV file and drop 'timeSignature' column\n","def load_csv(filename):\n","    dataset = list()\n","    with open(filename, 'r') as file:\n","        csv_reader = reader(file)\n","        header = next(csv_reader, None)  # Read the header\n","        if 'timeSignature' in header:\n","          index = header.index('timeSignature')\n","        for row in csv_reader:\n","             if not row:\n","                continue\n","             del row[index]\n","             dataset.append(row)\n","    dataset = dataset[1:]\n","    return dataset\n","\n","\n","# Convert string column to float\n","def str_column_to_float(dataset, column):\n","\tfor row in dataset:\n","\t\trow[column] = float(row[column].strip())\n","\n","# Convert string column to integer\n","def str_column_to_int(dataset, column):\n","\tclass_values = [row[column] for row in dataset]\n","\tunique = set(class_values)\n","\tlookup = dict()\n","\tfor i, value in enumerate(unique):\n","\t\tlookup[value] = i\n","\tfor row in dataset:\n","\t\trow[column] = lookup[row[column]]\n","\treturn lookup\n","\n","# Find the min and max values for each column\n","def dataset_minmax(dataset):\n","\tminmax = list()\n","\tfor i in range(len(dataset[0])-1):\n","\t\tcol_values = [row[i] for row in dataset]\n","\t\tvalue_min = min(col_values)\n","\t\tvalue_max = max(col_values)\n","\t\tminmax.append([value_min, value_max])\n","\treturn minmax\n","\n","# Rescale dataset columns to the range 0-1\n","def normalize_dataset(dataset):\n","    # Exclude the last column when calculating mean and standard deviation\n","    dataset_array = np.array(dataset)\n","    #print(dataset_array)\n","    # Exclude the last column when calculating mean and standard deviation\n","    means = np.mean(dataset_array[:, :-1].astype(float), axis=0)\n","    stds = np.std(dataset_array[:, :-1].astype(float), axis=0)\n","\n","    # Apply standard deviation normalization\n","    for row in dataset:\n","        for i in range(len(row)-1):  # Exclude the last column\n","            row[i] = (row[i] - means[i]) / stds[i]\n","\n","# Split a dataset into k folds\n","def cross_validation_split(dataset, n_folds):\n","\tdataset_split = list()\n","\tdataset_copy = list(dataset)\n","\tfold_size = int(len(dataset) / n_folds)\n","\tfor _ in range(n_folds):\n","\t\tfold = list()\n","\t\twhile len(fold) < fold_size:\n","\t\t\tindex = randrange(len(dataset_copy))\n","\t\t\tfold.append(dataset_copy.pop(index))\n","\t\tdataset_split.append(fold)\n","\treturn dataset_split\n","\n","# Calculate accuracy percentage\n","def accuracy_metric(actual, predicted):\n","\tcorrect = 0\n","\tfor i in range(len(actual)):\n","\t\tif actual[i] == predicted[i]:\n","\t\t\tcorrect += 1\n","\treturn correct / float(len(actual)) * 100.0\n","\n","# Evaluate an algorithm using a cross validation split\n","def evaluate_algorithm(dataset, algorithm, n_folds, *args):\n","\tfolds = cross_validation_split(dataset, n_folds)\n","\tscores = list()\n","\tfor fold in folds:\n","\t\ttrain_set = list(folds)\n","\t\ttrain_set.remove(fold)\n","\t\ttrain_set = sum(train_set, [])\n","\t\ttest_set = list()\n","\t\tfor row in fold:\n","\t\t\trow_copy = list(row)\n","\t\t\ttest_set.append(row_copy)\n","\t\t\trow_copy[-1] = None\n","\t\tpredicted = algorithm(train_set, test_set, *args)\n","\t\tactual = [row[-1] for row in fold]\n","\t\taccuracy = accuracy_metric(actual, predicted)\n","\t\tscores.append(accuracy)\n","\treturn scores\n","\n","# Calculate the Euclidean distance between two vectors\n","def euclidean_distance(row1, row2):\n","\tdistance = 0.0\n","\tfor i in range(len(row1)-1):\n","\t\tdistance += (row1[i] - row2[i])**2\n","\treturn sqrt(distance)\n","\n","# Locate the most similar neighbors\n","def get_neighbors(train, test_row, num_neighbors):\n","\tdistances = list()\n","\tfor train_row in train:\n","\t\tdist = euclidean_distance(test_row, train_row)\n","\t\tdistances.append((train_row, dist))\n","\tdistances.sort(key=lambda tup: tup[1])\n","\tneighbors = list()\n","\tfor i in range(num_neighbors):\n","\t\tneighbors.append(distances[i][0])\n","\treturn neighbors\n","\n","# Make a prediction with neighbors\n","def predict_classification(train, test_row, num_neighbors):\n","\tneighbors = get_neighbors(train, test_row, num_neighbors)\n","\toutput_values = [row[-1] for row in neighbors]\n","\tprediction = max(set(output_values), key=output_values.count)\n","\treturn prediction\n","\n","# kNN Algorithm\n","def k_nearest_neighbors(train, test, num_neighbors):\n","\tpredictions = list()\n","\tfor row in test:\n","\t\toutput = predict_classification(train, row, num_neighbors)\n","\t\tpredictions.append(output)\n","\treturn(predictions)\n","\n","seed(1)\n","filename = 'final_train.csv'\n","dataset = load_csv(filename)\n","# for row in dataset:\n","#   print(row)\n","for i in range(len(dataset[0])-1):\n","\tstr_column_to_float(dataset, i)\n","#minimax = dataset_minmax(dataset)\n","normalize_dataset(dataset)\n","\n","# convert class column to integers\n","str_column_to_int(dataset, len(dataset[0])-1)\n","# evaluate algorithm\n","n_folds = 5\n","num_neighbors = 5\n","scores = evaluate_algorithm(dataset, k_nearest_neighbors, n_folds, num_neighbors)\n","print('Scores: %s' % scores)\n","print('Mean Accuracy: %.3f%%' % (sum(scores)/float(len(scores))))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UGnorPSHlXSK","outputId":"c65bdf0a-be51-4b85-830d-4df4189560f3","executionInfo":{"status":"ok","timestamp":1714128184093,"user_tz":-330,"elapsed":8174,"user":{"displayName":"Ankita Kanoji","userId":"09403614458321710924"}}},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Scores: [67.9054054054054, 64.52702702702703, 66.8918918918919, 68.91891891891892, 67.22972972972973]\n","Mean Accuracy: 67.095%\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","from sklearn.preprocessing import StandardScaler\n","\n","def load_dataset(csv_file):\n","    return pd.read_csv(csv_file)\n","\n","def prepare_data(df, target_column):\n","    X = df.drop(columns=[target_column]).values  # Features\n","    y = df[target_column].values  # Class labels\n","    return X, y\n","\n","def knn_classification(X, y, k_neighbors=5, n_splits=5):\n","\n","    from sklearn.model_selection import cross_val_score, KFold\n","    from sklearn.neighbors import KNeighborsClassifier\n","    from sklearn.preprocessing import StandardScaler\n","\n","    # Initialize KNN classifier\n","    knn = KNeighborsClassifier(n_neighbors=k_neighbors)\n","\n","    # Scale the features using StandardScaler\n","    scaler = StandardScaler()\n","    X_scaled = scaler.fit_transform(X)\n","\n","    # Define cross-validation\n","    kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n","\n","    # Perform cross-validation and calculate accuracy\n","    cv_scores = cross_val_score(knn, X_scaled, y, cv=kf, scoring='accuracy')\n","\n","    # Calculate mean accuracy\n","    mean_accuracy = cv_scores.mean()\n","\n","    return mean_accuracy\n","\n","# Example usage:\n","csv_file = \"final_train.csv\"  # Replace with the path to your CSV file\n","target_column = \"mood\"  # Replace with the name of your class label column\n","\n","# Load dataset\n","df = load_dataset(csv_file)\n","\n","# Prepare features (X) and class labels (y)\n","X, y = prepare_data(df, target_column)\n","\n","# Perform KNN classification with 5-fold cross-validation\n","mean_accuracy = knn_classification(X, y)\n","\n","print(\"Mean Accuracy:\", mean_accuracy*100, \"%\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"e5dM0wpLIauP","outputId":"0de9d543-6063-4c3d-a131-33008f02e6e4","executionInfo":{"status":"ok","timestamp":1714128190140,"user_tz":-330,"elapsed":803,"user":{"displayName":"Ankita Kanoji","userId":"09403614458321710924"}}},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Mean Accuracy: 67.31845481845482 %\n"]}]}]}